{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport glob\nimport time\nimport numpy as np\nfrom PIL import Image\nfrom pathlib import Path\nfrom tqdm.notebook import tqdm\nimport matplotlib.pyplot as plt\nfrom skimage.color import rgb2lab, lab2rgb\nimport cv2\nimport torchvision\nfrom torchvision import models\nimport torch.nn.functional as F\n\nimport scipy\nimport torch\nimport torchvision.datasets as dset\nfrom torch import nn, optim\nfrom torchvision import transforms\nfrom torch.utils.data import Dataset, DataLoader\nnp.random.seed(2021)\ntorch.manual_seed(2021)\nimport copy","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-01-17T01:40:47.655555Z","iopub.execute_input":"2022-01-17T01:40:47.656269Z","iopub.status.idle":"2022-01-17T01:40:49.926845Z","shell.execute_reply.started":"2022-01-17T01:40:47.656165Z","shell.execute_reply":"2022-01-17T01:40:49.926096Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"# **Defining Dataset**","metadata":{}},{"cell_type":"code","source":"data_root = \"../input/flickrfaceshq-dataset-ffhq\"\n\nclass FaceData(torch.utils.data.Dataset):\n    def __init__(self, transformations=None, root = '../input/flickrfaceshq-dataset-ffhq'):\n        self.root = root\n        self.transformations = transformations\n        self.img_list = glob.glob(os.path.join(root,'*'))\n        self.img_list.sort()\n    \n    def __len__(self):\n        return len(glob.glob(\"../input/flickrfaceshq-dataset-ffhq/*\"))\n\n        \n    def __getitem__(self, idx):\n        ip_img = Image.open(self.img_list[idx])\n        ip_img = ip_img.resize((224,224))\n        \n        ip_img = np.array(ip_img)\n        img_lab = rgb2lab(ip_img).astype(\"float32\")\n        img_lab = transforms.ToTensor()(img_lab)\n\n        L = img_lab[[0]] / 50. - 1. # Max for L is 100 so need /50 -1 to get b/w -1,1\n        ab = img_lab[[1,2]]/100. #Max for a and b is 127\n        \n        return L, ab\n        ","metadata":{"execution":{"iopub.status.busy":"2022-01-17T01:40:49.928673Z","iopub.execute_input":"2022-01-17T01:40:49.928916Z","iopub.status.idle":"2022-01-17T01:40:49.937812Z","shell.execute_reply.started":"2022-01-17T01:40:49.928884Z","shell.execute_reply":"2022-01-17T01:40:49.936814Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"data_set = FaceData()\n\nindices = list(range(30000))\n\ntrain_indices,val_indices = indices[:20000], indices[20000:25000]\n\ntrain_sampler = torch.utils.data.sampler.SubsetRandomSampler(train_indices)\nval_sampler = torch.utils.data.sampler.SubsetRandomSampler(val_indices)\n\ntrain_data = torch.utils.data.DataLoader(data_set,batch_size =64, sampler=train_sampler,\n                                        num_workers = 2)\nval_data = torch.utils.data.DataLoader(data_set,batch_size = 32, sampler =val_sampler,\n                                      num_workers =2)\nprint(f'Train_data_size={len(train_data)}; Val_data_size={len(val_data)}')","metadata":{"execution":{"iopub.status.busy":"2022-01-17T01:40:49.939198Z","iopub.execute_input":"2022-01-17T01:40:49.939453Z","iopub.status.idle":"2022-01-17T01:40:53.020749Z","shell.execute_reply.started":"2022-01-17T01:40:49.939420Z","shell.execute_reply":"2022-01-17T01:40:53.019984Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"# **Defining Model**","metadata":{}},{"cell_type":"code","source":"class Image_Colorization_Model(nn.Module):\n    def __init__(self):\n        super(Image_Colorization_Model, self).__init__()\n#         Encoder\n        self.conv_preprocess1 = nn.Conv2d(1, 3, kernel_size=3, padding=1)\n        self.conv_preprocess2 = nn.Conv2d(3, 3, kernel_size=3, padding=1)\n        model_resnet = models.resnet50(pretrained=True)\n        self.conv1 = model_resnet.conv1\n        self.bn1 = model_resnet.bn1\n        self.relu = model_resnet.relu\n        self.maxpool = model_resnet.maxpool\n        self.layer1 = model_resnet.layer1\n        self.layer2 = model_resnet.layer2\n#         Decoder\n        self.upsample = nn.Upsample(scale_factor = 2, mode = 'nearest')\n        self.conv_decode2_1 = nn.Conv2d(768, 128, kernel_size=3, padding=1)\n        self.conv_decode2_2 = nn.Conv2d(128, 64, kernel_size=3, padding=1)\n        \n        self.conv_decode1_1 = nn.Conv2d(128, 16, kernel_size=3, padding=1)\n        self.conv_decode1_2 = nn.Conv2d(16, 8, kernel_size=3, padding=1)\n        \n        self.conv_decode0_1 = nn.Conv2d(11, 4, kernel_size=3, padding=1)\n        self.conv_decode0_2 = nn.Conv2d(4, 2, kernel_size=1)\n        \n        \n        \n    def forward(self,x):\n        ######ENCODER############\n        x_pre = F.relu(self.conv_preprocess1(x))\n        x_pre = F.relu(self.conv_preprocess2(x_pre))\n        \n        encode_1 = self.conv1(x_pre)\n        encode_1 = self.bn1(encode_1)\n        encode_1 = self.relu(encode_1)\n        \n        x_mp = self.maxpool(encode_1)\n        \n        encode_2 = self.layer1(x_mp)\n        bottle_neck = self.layer2(encode_2)\n        \n        ########DECODER#########\n        decode_2 = self.upsample(bottle_neck)\n        decode_2 = torch.cat((encode_2,decode_2),dim=1)\n#         print(decode_2.shape)\n        decode_2 = F.relu(self.conv_decode2_1(decode_2))\n        decode_2 = F.relu(self.conv_decode2_2(decode_2))\n        \n        decode_1 = self.upsample(decode_2)\n        decode_1 = torch.cat((encode_1,decode_1),dim=1)\n        decode_1 = F.relu(self.conv_decode1_1(decode_1))\n        decode_1 = F.relu(self.conv_decode1_2(decode_1))\n        \n        decode_pre = self.upsample(decode_1)\n        decode_pre = torch.cat((x_pre,decode_pre),dim=1)\n        decode_pre = F.relu(self.conv_decode0_1(decode_pre))\n        decode_pre = F.relu(self.conv_decode0_2(decode_pre))\n        \n        return decode_pre","metadata":{"execution":{"iopub.status.busy":"2022-01-17T01:40:53.022069Z","iopub.execute_input":"2022-01-17T01:40:53.022485Z","iopub.status.idle":"2022-01-17T01:40:53.038528Z","shell.execute_reply.started":"2022-01-17T01:40:53.022447Z","shell.execute_reply":"2022-01-17T01:40:53.037829Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"device = 'cuda' if torch.cuda.is_available() else 'cpu'\nlearning_rate = 1e-3\n# encoder_model = ResNet().to(device)\n# decoder_model = Decoder(device).to(device)\n# print(next(decoder_model.parameters()).device)\nmodel = Image_Colorization_Model().cuda()\n# model = model.to(device)\noptimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\nL1loss = nn.L1Loss()\nos.mkdir('./weights')","metadata":{"execution":{"iopub.status.busy":"2022-01-17T01:40:53.041536Z","iopub.execute_input":"2022-01-17T01:40:53.041738Z","iopub.status.idle":"2022-01-17T01:41:02.044703Z","shell.execute_reply.started":"2022-01-17T01:40:53.041715Z","shell.execute_reply":"2022-01-17T01:41:02.043919Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"# **Training Colorization Model**","metadata":{}},{"cell_type":"code","source":"# os.mkdir('./weights')\n# def plot_loss_L1(train_list):\n#     plt.figure(figsize=(20,20))\n#     plt.plot(train_list,label='Train loss L1')\n#     plt.xlabel('Iteration')\n#     plt.ylabel('L1 Loss')\n#     plt.legend(loc='upper right')\n#     plt.savefig(os.path.join('./', 'Loss_graph_L1'))\n#     plt.close()\n\n# def plot_loss_mse(train_list):\n#     plt.figure(figsize=(20,20))\n#     plt.plot(train_list,label='Train loss MSE')\n#     plt.xlabel('Iteration')\n#     plt.ylabel('MSE Loss')\n#     plt.legend(loc='upper right')\n#     plt.savefig(os.path.join(os.path.join('./', 'Loss_graph_mse')))\n#     plt.close()\n\n# model.train()\n\n# train_loss_l1 = []\n# train_loss_mse = []\n\n# for i in range(70):#Total=70 epoch\n# #     b=0\n#     for data in train_data:\n# #         print(len(data))\n#         gray = data[0].to(device)  \n# #         plt.imshow(gray)\n#         true_ab_space = data[1].to(device)\n#         optimizer.zero_grad()\n# #         print(f'x:{gray.shape}')\n# #         print(f'y:{true_ab_space.shape}')\n              \n#         predicted_ab_space = model(gray)\n# #         print(predicted_ab_space.shape)\n# #         print(true_ab_space.shape)\n#         loss = L1loss(predicted_ab_space, true_ab_space)\n    \n#         train_loss_l1.append(loss.item())\n#         train_loss_mse.append((F.mse_loss(predicted_ab_space, true_ab_space)).item())\n# #         loss = F.mse_loss(predicted_ab_space, true_ab_space)\n        \n#         loss.backward()\n# #         print(loss)\n# #         b+=1\n# #         print(b)\n#         optimizer.step()\n        \n# #         plot_loss_L1(train_loss_l1)\n# #         plot_loss_mse(train_loss_mse)\n        \n#     if (i+1) % 10 == 0:\n#         print('%d iterations' % (i+1))\n#         print('L1_Loss %.3f' % np.mean(train_loss_l1[-100:]))\n#         print('MSE_Loss: %.3f' % np.mean(train_loss_mse[-100:]))\n#         print()\n\n#     if (i+1)%5 == 0:\n#         torch.save({'epoch':i,\n#                     'model_state_dict':model.state_dict(),\n#                     'optimizer_state_dict':optimizer.state_dict(),\n#                     'loss':{'L1_Loss':train_loss_l1.copy(),'MSE_Loss':train_loss_mse.copy()},\n#                    },os.path.join('./weights',f'_epoch_{i+1}'))","metadata":{"execution":{"iopub.status.busy":"2022-01-17T01:41:02.049536Z","iopub.execute_input":"2022-01-17T01:41:02.051635Z","iopub.status.idle":"2022-01-17T01:41:02.059708Z","shell.execute_reply.started":"2022-01-17T01:41:02.051594Z","shell.execute_reply":"2022-01-17T01:41:02.058948Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"# **Testing Trained Model**","metadata":{}},{"cell_type":"code","source":"# torch.cuda.memory_allocated(), torch.cuda.current_device()","metadata":{"execution":{"iopub.status.busy":"2022-01-17T01:41:02.064049Z","iopub.execute_input":"2022-01-17T01:41:02.066610Z","iopub.status.idle":"2022-01-17T01:41:02.074504Z","shell.execute_reply.started":"2022-01-17T01:41:02.066572Z","shell.execute_reply":"2022-01-17T01:41:02.073629Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"chkpt = torch.load(\"../input/color-model-epoch-70/_epoch_70 (1)\",map_location=torch.device('cpu'))\nmodel.load_state_dict(chkpt['model_state_dict'])\n\nmodel.eval()\n\nwith torch.no_grad():\n    (gray_val, true_ab_val) = next(iter(val_data))\n    \n    gray_val_orig = copy.deepcopy(gray_val)\n    true_ab_val_orig = copy.deepcopy(true_ab_val)\n    \n    gray_val = gray_val.to(device)\n\n    pred_ab = model(gray_val)\n\npred_ab = (pred_ab*100.).permute(0, 2, 3, 1).contiguous()\ngray_val = ((gray_val+1)*50.).permute(0,2,3,1).contiguous()\n\nab_rgb = (true_ab_val_orig*100.).permute(0, 2, 3, 1).contiguous()\ngray_rgb = ((gray_val_orig+1)*50.).permute(0,2,3,1).contiguous()\n\ntrue_rgb = torch.tensor(lab2rgb(torch.cat((gray_rgb,ab_rgb),dim=3).cpu()))\ntrue_rgb = true_rgb.permute(0,3,1,2)\n# gray_val_orig = gray_val_orig.cpu().numpy().transpose(0,2,3,1)\n\n# pred_ab = (pred_ab*100.).cpu().numpy().transpose(0,2,3,1)\n# gray_val = ((gray_val+1)*50.).cpu().numpy().transpose(0,2,3,1)\n# pred_lab = np.concatenate((gray_val,pred_ab),axis=3)\n# print(pred_ab.shape,gray_val.shape,pred_lab.shape)\n# pred_rgb =  lab2rgb(pred_lab)\n\npred_rgb = torch.tensor(lab2rgb(torch.cat((gray_val,pred_ab),dim=3).cpu()))\npred_rgb = pred_rgb.permute(0,3,1,2)","metadata":{"execution":{"iopub.status.busy":"2022-01-17T01:41:02.078237Z","iopub.execute_input":"2022-01-17T01:41:02.078461Z","iopub.status.idle":"2022-01-17T01:41:11.583465Z","shell.execute_reply.started":"2022-01-17T01:41:02.078428Z","shell.execute_reply":"2022-01-17T01:41:11.582566Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"from torchvision.utils import make_grid\ndef show(img):\n#     print(img.shape)\n    npimg = img.numpy()\n    npimg = img\n    print(npimg.shape)\n    _, ax = plt.subplots(figsize=(20,20))\n    fig = ax.imshow(np.transpose(npimg, (1,2,0)))\n    fig.axes.get_xaxis().set_visible(True)\n    fig.axes.get_yaxis().set_visible(True)\n    plt.savefig(\"./output\")\n\nshow(make_grid(pred_rgb.cpu().data) )\n# show(pred_rgb[0])","metadata":{"execution":{"iopub.status.busy":"2022-01-17T01:41:11.585173Z","iopub.execute_input":"2022-01-17T01:41:11.585456Z","iopub.status.idle":"2022-01-17T01:41:13.485724Z","shell.execute_reply.started":"2022-01-17T01:41:11.585418Z","shell.execute_reply":"2022-01-17T01:41:13.483680Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"show(make_grid(((gray_val/100.)).permute(0,3,1,2).cpu().data))","metadata":{"execution":{"iopub.status.busy":"2022-01-17T01:41:13.486678Z","iopub.execute_input":"2022-01-17T01:41:13.486908Z","iopub.status.idle":"2022-01-17T01:41:14.848916Z","shell.execute_reply.started":"2022-01-17T01:41:13.486880Z","shell.execute_reply":"2022-01-17T01:41:14.848344Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"show(make_grid(true_rgb.cpu().data) )","metadata":{"execution":{"iopub.status.busy":"2022-01-17T01:41:14.850131Z","iopub.execute_input":"2022-01-17T01:41:14.850515Z","iopub.status.idle":"2022-01-17T01:41:16.737153Z","shell.execute_reply.started":"2022-01-17T01:41:14.850478Z","shell.execute_reply":"2022-01-17T01:41:16.736468Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"pip install torch-summary","metadata":{"execution":{"iopub.status.busy":"2022-01-17T01:41:16.738337Z","iopub.execute_input":"2022-01-17T01:41:16.738668Z","iopub.status.idle":"2022-01-17T01:41:26.301876Z","shell.execute_reply.started":"2022-01-17T01:41:16.738638Z","shell.execute_reply":"2022-01-17T01:41:26.301013Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"from torchsummary import summary\nsummary(model, (1, 224, 224))","metadata":{"execution":{"iopub.status.busy":"2022-01-17T01:41:26.303678Z","iopub.execute_input":"2022-01-17T01:41:26.303960Z","iopub.status.idle":"2022-01-17T01:41:26.345028Z","shell.execute_reply.started":"2022-01-17T01:41:26.303920Z","shell.execute_reply":"2022-01-17T01:41:26.344381Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"loss = chkpt['loss']['L1_Loss']\nprint(len(loss))\nf = plt.figure(figsize=(20,8))\nax = f.add_subplot(1,2,1)\nax.plot(loss)\n# ax.set_yscale('log')\nax.set_title('L1 Loss')\nax.set_xlabel('Iteration')\nf.savefig('./loss')","metadata":{"execution":{"iopub.status.busy":"2022-01-17T01:41:26.347843Z","iopub.execute_input":"2022-01-17T01:41:26.348309Z","iopub.status.idle":"2022-01-17T01:41:26.667274Z","shell.execute_reply.started":"2022-01-17T01:41:26.348271Z","shell.execute_reply":"2022-01-17T01:41:26.666586Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"loss = chkpt['loss']['MSE_Loss']\nf = plt.figure(figsize=(20,8))\nax = f.add_subplot(1,2,1)\nax.plot(loss)\n# ax.set_yscale('log')\nax.set_title('MSE_Loss Loss')\nax.set_xlabel('Iteration')","metadata":{"execution":{"iopub.status.busy":"2022-01-17T01:41:26.668363Z","iopub.execute_input":"2022-01-17T01:41:26.669479Z","iopub.status.idle":"2022-01-17T01:41:26.902897Z","shell.execute_reply.started":"2022-01-17T01:41:26.669427Z","shell.execute_reply":"2022-01-17T01:41:26.902160Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}