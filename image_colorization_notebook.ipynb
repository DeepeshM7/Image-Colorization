{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport glob\nimport time\nimport numpy as np\nfrom PIL import Image\nfrom pathlib import Path\nfrom tqdm.notebook import tqdm\nimport matplotlib.pyplot as plt\nfrom skimage.color import rgb2lab, lab2rgb\nimport cv2\nimport torchvision\nfrom torchvision import models\nimport torch.nn.functional as F\n\nimport scipy\nimport torch\nimport torchvision.datasets as dset\nfrom torch import nn, optim\nfrom torchvision import transforms\nfrom torch.utils.data import Dataset, DataLoader\nnp.random.seed(2021)\ntorch.manual_seed(2021)\nimport copy","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-01-12T05:43:19.669267Z","iopub.execute_input":"2022-01-12T05:43:19.669535Z","iopub.status.idle":"2022-01-12T05:43:19.677430Z","shell.execute_reply.started":"2022-01-12T05:43:19.669505Z","shell.execute_reply":"2022-01-12T05:43:19.676645Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"# **Defining Dataset**","metadata":{}},{"cell_type":"code","source":"data_root = \"../input/flickrfaceshq-dataset-ffhq\"\n\nclass FaceData(torch.utils.data.Dataset):\n    def __init__(self, transformations=None, root = '../input/flickrfaceshq-dataset-ffhq'):\n        self.root = root\n        self.transformations = transformations\n        self.img_list = glob.glob(os.path.join(root,'*'))\n        self.img_list.sort()\n    \n    def __len__(self):\n        return len(glob.glob(\"../input/flickrfaceshq-dataset-ffhq/*\"))\n\n        \n    def __getitem__(self, idx):\n        ip_img = Image.open(self.img_list[idx])#.convert(\"RGB\")\n        ip_img = ip_img.resize((224,224))\n        \n        ip_img = np.array(ip_img)\n        img_lab = rgb2lab(ip_img).astype(\"float32\") # Converting RGB to L*a*b\n        img_lab = transforms.ToTensor()(img_lab)\n\n        L = img_lab[[0]] / 50. - 1. # Max for L is 100 so need /50 -1 to get b/w -1,1\n        ab = img_lab[[1,2]]/100. #Max for a and b is 127\n        \n        return L, ab\n        ","metadata":{"execution":{"iopub.status.busy":"2022-01-12T02:22:41.974701Z","iopub.execute_input":"2022-01-12T02:22:41.974961Z","iopub.status.idle":"2022-01-12T02:22:41.983847Z","shell.execute_reply.started":"2022-01-12T02:22:41.974926Z","shell.execute_reply":"2022-01-12T02:22:41.982920Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"data_set = FaceData()\n\nsample_loader = torch.utils.data.DataLoader(data_set, batch_size=32)\n\n# sample_batch=next(iter(sample_loader))\n# len(sample_batch)\n\n# type(sample_batch[0]),sample_batch[0].shape,sample_batch[1].shape\n# concat_lab=torch.cat((sample_batch[0],sample_batch[1]),dim=1)\n# concat_lab.shape\n# concat_rgb = lab2rgb(torch.cat(((sample_batch[0]+1)*50.,sample_batch[1]*100.),dim=1).permute(0,2,3,1))\n\n# concat_rgb = torch.tensor(concat_rgb).permute(0,3,1,2)\n\n# grid1 = torchvision.utils.make_grid(sample_batch[0],nrow=16)\n# grid2 = torchvision.utils.make_grid(concat_lab,nrow=16)\n# grid3 =  torchvision.utils.make_grid(concat_rgb,nrow=16)\n\n# fig, axs = plt.subplots(3,1,figsize=(50,50),sharex=True)#2 rows, 1 column\n\n# axs[0].imshow(np.transpose(grid1,(1,2,0)))\n# axs[1].imshow(np.transpose(grid2,(1,2,0)))\n# axs[2].imshow(np.transpose(grid3,(1,2,0)))\n\n# plt.subplots_adjust(top=0.5)","metadata":{"execution":{"iopub.status.busy":"2022-01-12T02:22:41.986020Z","iopub.execute_input":"2022-01-12T02:22:41.986592Z","iopub.status.idle":"2022-01-12T02:22:42.515533Z","shell.execute_reply.started":"2022-01-12T02:22:41.986535Z","shell.execute_reply":"2022-01-12T02:22:42.514561Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# indices = list(range(len(data_set.img_list)))\n# val_split = int(0.9*len(data_set.img_list)) \n# test_split = int(val_split+ ((len(data_set.img_list)-val_split)//2))\nindices = list(range(30000))\n\n# train_indices,val_indices,test_indices = indices[:20000], indices[20000:25000],indices[25000:30000]\ntrain_indices,val_indices,test_indices = indices[:20000], indices[20000:25000],indices[25000:30000]\n\ntrain_sampler = torch.utils.data.sampler.SubsetRandomSampler(train_indices)\nval_sampler = torch.utils.data.sampler.SubsetRandomSampler(val_indices)\ntest_sampler = torch.utils.data.sampler.SubsetRandomSampler(test_indices)\n\ntrain_data = torch.utils.data.DataLoader(data_set,batch_size =64, sampler=train_sampler,\n                                        num_workers = 2)\nval_data = torch.utils.data.DataLoader(data_set,batch_size = 32, sampler =val_sampler,\n                                      num_workers =2)\ntest_data = torch.utils.data.DataLoader(data_set,batch_size = 32, sampler =test_sampler,\n                                      num_workers =2)\nprint(f'Train_data_size={len(train_data)}; Val_data_size={len(val_data)} ; Test_data_size={len(test_data)}')","metadata":{"execution":{"iopub.status.busy":"2022-01-12T02:22:42.518333Z","iopub.execute_input":"2022-01-12T02:22:42.518558Z","iopub.status.idle":"2022-01-12T02:22:42.531610Z","shell.execute_reply.started":"2022-01-12T02:22:42.518529Z","shell.execute_reply":"2022-01-12T02:22:42.530610Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"# **Defining Model**","metadata":{}},{"cell_type":"code","source":"class Image_Colorization_Model(nn.Module):\n    def __init__(self):\n        super(Image_Colorization_Model, self).__init__()\n#         Encoder\n        self.conv_preprocess1 = nn.Conv2d(1, 3, kernel_size=3, padding=1)\n        self.conv_preprocess2 = nn.Conv2d(3, 3, kernel_size=3, padding=1)\n        model_resnet = models.resnet50(pretrained=True)\n        self.conv1 = model_resnet.conv1\n        self.bn1 = model_resnet.bn1\n        self.relu = model_resnet.relu\n        self.maxpool = model_resnet.maxpool\n        self.layer1 = model_resnet.layer1\n        self.layer2 = model_resnet.layer2\n#         Decoder\n        self.upsample = nn.Upsample(scale_factor = 2, mode = 'nearest')\n        self.conv_decode2_1 = nn.Conv2d(768, 128, kernel_size=3, padding=1)\n        self.conv_decode2_2 = nn.Conv2d(128, 64, kernel_size=3, padding=1)\n        \n        self.conv_decode1_1 = nn.Conv2d(128, 16, kernel_size=3, padding=1)\n        self.conv_decode1_2 = nn.Conv2d(16, 8, kernel_size=3, padding=1)\n        \n        self.conv_decode0_1 = nn.Conv2d(11, 4, kernel_size=3, padding=1)\n        self.conv_decode0_2 = nn.Conv2d(4, 2, kernel_size=1)\n        \n        \n        \n    def forward(self,x):\n        ######ENCODER############\n        x_pre = F.relu(self.conv_preprocess1(x))\n        x_pre = F.relu(self.conv_preprocess2(x_pre))\n        \n        encode_1 = self.conv1(x_pre)\n        encode_1 = self.bn1(encode_1)\n        encode_1 = self.relu(encode_1)\n        \n        x_mp = self.maxpool(encode_1)\n        \n        encode_2 = self.layer1(x_mp)\n        bottle_neck = self.layer2(encode_2)\n        \n        ########DECODER#########\n        decode_2 = self.upsample(bottle_neck)\n        decode_2 = torch.cat((encode_2,decode_2),dim=1)\n#         print(decode_2.shape)\n        decode_2 = F.relu(self.conv_decode2_1(decode_2))\n        decode_2 = F.relu(self.conv_decode2_2(decode_2))\n        \n        decode_1 = self.upsample(decode_2)\n        decode_1 = torch.cat((encode_1,decode_1),dim=1)\n        decode_1 = F.relu(self.conv_decode1_1(decode_1))\n        decode_1 = F.relu(self.conv_decode1_2(decode_1))\n        \n        decode_pre = self.upsample(decode_1)\n        decode_pre = torch.cat((x_pre,decode_pre),dim=1)\n        decode_pre = F.relu(self.conv_decode0_1(decode_pre))\n        decode_pre = F.relu(self.conv_decode0_2(decode_pre))\n        \n        return decode_pre","metadata":{"execution":{"iopub.status.busy":"2022-01-12T02:22:42.533521Z","iopub.execute_input":"2022-01-12T02:22:42.534166Z","iopub.status.idle":"2022-01-12T02:22:42.556947Z","shell.execute_reply.started":"2022-01-12T02:22:42.534119Z","shell.execute_reply":"2022-01-12T02:22:42.555875Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"device = 'cuda' if torch.cuda.is_available() else 'cpu'\nlearning_rate = 1e-3\n# encoder_model = ResNet().to(device)\n# decoder_model = Decoder(device).to(device)\n# print(next(decoder_model.parameters()).device)\nmodel = Image_Colorization_Model().cuda()\n# model = model.to(device)\noptimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\nL1loss = nn.L1Loss()\nos.mkdir('./weights')","metadata":{"execution":{"iopub.status.busy":"2022-01-12T02:22:42.558601Z","iopub.execute_input":"2022-01-12T02:22:42.559165Z","iopub.status.idle":"2022-01-12T02:22:48.048632Z","shell.execute_reply.started":"2022-01-12T02:22:42.559116Z","shell.execute_reply":"2022-01-12T02:22:48.047228Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"# **Training Colorization Model**","metadata":{}},{"cell_type":"code","source":"# os.mkdir('./weights')\n# def plot_loss_L1(train_list):\n#     plt.figure(figsize=(20,20))\n#     plt.plot(train_list,label='Train loss L1')\n#     plt.xlabel('Iteration')\n#     plt.ylabel('L1 Loss')\n#     plt.legend(loc='upper right')\n#     plt.savefig(os.path.join('./', 'Loss_graph_L1'))\n#     plt.close()\n\n# def plot_loss_mse(train_list):\n#     plt.figure(figsize=(20,20))\n#     plt.plot(train_list,label='Train loss MSE')\n#     plt.xlabel('Iteration')\n#     plt.ylabel('MSE Loss')\n#     plt.legend(loc='upper right')\n#     plt.savefig(os.path.join(os.path.join('./', 'Loss_graph_mse')))\n#     plt.close()\n\n# model.train()\n\n# train_loss_l1 = []\n# train_loss_mse = []\n\n# for i in range(70):#Total=70 epoch\n# #     b=0\n#     for data in train_data:\n# #         print(len(data))\n#         gray = data[0].to(device)  \n# #         plt.imshow(gray)\n#         true_ab_space = data[1].to(device)\n#         optimizer.zero_grad()\n# #         print(f'x:{gray.shape}')\n# #         print(f'y:{true_ab_space.shape}')\n              \n#         predicted_ab_space = model(gray)\n# #         print(predicted_ab_space.shape)\n# #         print(true_ab_space.shape)\n#         loss = L1loss(predicted_ab_space, true_ab_space)\n    \n#         train_loss_l1.append(loss.item())\n#         train_loss_mse.append((F.mse_loss(predicted_ab_space, true_ab_space)).item())\n# #         loss = F.mse_loss(predicted_ab_space, true_ab_space)\n        \n#         loss.backward()\n# #         print(loss)\n# #         b+=1\n# #         print(b)\n#         optimizer.step()\n        \n# #         plot_loss_L1(train_loss_l1)\n# #         plot_loss_mse(train_loss_mse)\n        \n#     if (i+1) % 10 == 0:\n#         print('%d iterations' % (i+1))\n#         print('L1_Loss %.3f' % np.mean(train_loss_l1[-100:]))\n#         print('MSE_Loss: %.3f' % np.mean(train_loss_mse[-100:]))\n#         print()\n\n#     if (i+1)%5 == 0:\n#         torch.save({'epoch':i,\n#                     'model_state_dict':model.state_dict(),\n#                     'optimizer_state_dict':optimizer.state_dict(),\n#                     'loss':{'L1_Loss':train_loss_l1.copy(),'MSE_Loss':train_loss_mse.copy()},\n#                    },os.path.join('./weights',f'_epoch_{i+1}'))","metadata":{"execution":{"iopub.status.busy":"2022-01-12T02:22:48.050156Z","iopub.execute_input":"2022-01-12T02:22:48.050603Z","iopub.status.idle":"2022-01-12T02:22:48.065655Z","shell.execute_reply.started":"2022-01-12T02:22:48.050561Z","shell.execute_reply":"2022-01-12T02:22:48.063726Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"# **Testing Trained Model**","metadata":{}},{"cell_type":"code","source":"# torch.cuda.memory_allocated(), torch.cuda.current_device()","metadata":{"execution":{"iopub.status.busy":"2022-01-12T02:22:48.070445Z","iopub.execute_input":"2022-01-12T02:22:48.072160Z","iopub.status.idle":"2022-01-12T02:22:48.089144Z","shell.execute_reply.started":"2022-01-12T02:22:48.072091Z","shell.execute_reply":"2022-01-12T02:22:48.087683Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"chkpt = torch.load(\"../input/color-model-epoch-70/_epoch_70 (1)\",map_location=torch.device('cpu'))\n# chkpt_inpaint = torch.load(\"../input/inpaint35/inpaint_epoch_35 (1)\",map_location=torch.device('cpu'))\nmodel.load_state_dict(chkpt['model_state_dict'])\n\n# inpaint_model.load_state_dict(chkpt_inpaint['model_state_dict'])\n\nmodel.eval()\n\nwith torch.no_grad():\n    (gray_val, true_ab_val) = next(iter(val_data))\n#     show(gray_val.cpu().numpy().transpose(0,2,3,1)[0])\n    \n    gray_val_orig = copy.deepcopy(gray_val)\n    true_ab_val_orig = copy.deepcopy(true_ab_val)\n    \n    gray_val = gray_val.to(device)\n\n    pred_ab = model(gray_val)\n\npred_ab = (pred_ab*100.).permute(0, 2, 3, 1).contiguous()\ngray_val = ((gray_val+1)*50.).permute(0,2,3,1).contiguous()\n\nab_rgb = (true_ab_val_orig*100.).permute(0, 2, 3, 1).contiguous()\ngray_rgb = ((gray_val_orig+1)*50.).permute(0,2,3,1).contiguous()\n\ntrue_rgb = torch.tensor(lab2rgb(torch.cat((gray_rgb,ab_rgb),dim=3).cpu()))\ntrue_rgb = true_rgb.permute(0,3,1,2)\n# gray_val_orig = gray_val_orig.cpu().numpy().transpose(0,2,3,1)\n\n# pred_ab = (pred_ab*100.).cpu().numpy().transpose(0,2,3,1)\n# gray_val = ((gray_val+1)*50.).cpu().numpy().transpose(0,2,3,1)\n# pred_lab = np.concatenate((gray_val,pred_ab),axis=3)\n# print(pred_ab.shape,gray_val.shape,pred_lab.shape)\n# pred_rgb =  lab2rgb(pred_lab)\n\npred_rgb = torch.tensor(lab2rgb(torch.cat((gray_val,pred_ab),dim=3).cpu()))\npred_rgb = pred_rgb.permute(0,3,1,2)","metadata":{"execution":{"iopub.status.busy":"2022-01-12T02:22:48.091113Z","iopub.execute_input":"2022-01-12T02:22:48.091553Z","iopub.status.idle":"2022-01-12T02:22:58.299919Z","shell.execute_reply.started":"2022-01-12T02:22:48.091460Z","shell.execute_reply":"2022-01-12T02:22:58.298773Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"from torchvision.utils import make_grid\ndef show(img):\n#     print(img.shape)\n    npimg = img.numpy()\n    npimg = img\n    print(npimg.shape)\n    _, ax = plt.subplots(figsize=(20,20))\n    fig = ax.imshow(np.transpose(npimg, (1,2,0)))\n    fig.axes.get_xaxis().set_visible(True)\n    fig.axes.get_yaxis().set_visible(True)\n    plt.savefig(\"./output\")\n\nshow(make_grid(pred_rgb.cpu().data) )\n# show(pred_rgb[0])","metadata":{"execution":{"iopub.status.busy":"2022-01-12T02:22:58.303633Z","iopub.execute_input":"2022-01-12T02:22:58.303908Z","iopub.status.idle":"2022-01-12T02:23:00.558339Z","shell.execute_reply.started":"2022-01-12T02:22:58.303859Z","shell.execute_reply":"2022-01-12T02:23:00.557212Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"show(make_grid(((gray_val/100.)).permute(0,3,1,2).cpu().data))","metadata":{"execution":{"iopub.status.busy":"2022-01-12T02:23:00.559768Z","iopub.execute_input":"2022-01-12T02:23:00.560181Z","iopub.status.idle":"2022-01-12T02:23:02.085169Z","shell.execute_reply.started":"2022-01-12T02:23:00.560139Z","shell.execute_reply":"2022-01-12T02:23:02.083526Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"show(make_grid(true_rgb.cpu().data) )","metadata":{"execution":{"iopub.status.busy":"2022-01-12T02:23:02.086536Z","iopub.execute_input":"2022-01-12T02:23:02.087429Z","iopub.status.idle":"2022-01-12T02:23:03.994980Z","shell.execute_reply.started":"2022-01-12T02:23:02.087385Z","shell.execute_reply":"2022-01-12T02:23:03.994097Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"pip install torch-summary","metadata":{"execution":{"iopub.status.busy":"2022-01-12T02:23:03.996509Z","iopub.execute_input":"2022-01-12T02:23:03.997421Z","iopub.status.idle":"2022-01-12T02:23:16.694291Z","shell.execute_reply.started":"2022-01-12T02:23:03.997377Z","shell.execute_reply":"2022-01-12T02:23:16.692991Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"from torchsummary import summary\nsummary(model, (1, 224, 224))","metadata":{"execution":{"iopub.status.busy":"2022-01-12T02:23:16.696678Z","iopub.execute_input":"2022-01-12T02:23:16.697059Z","iopub.status.idle":"2022-01-12T02:23:16.902598Z","shell.execute_reply.started":"2022-01-12T02:23:16.696998Z","shell.execute_reply":"2022-01-12T02:23:16.901403Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"loss = chkpt['loss']['L1_Loss']\nprint(len(loss))\nf = plt.figure(figsize=(20,8))\nax = f.add_subplot(1,2,1)\nax.plot(loss)\n# ax.set_yscale('log')\nax.set_title('L1 Loss')\nax.set_xlabel('Iteration')\nf.savefig('./loss')","metadata":{"execution":{"iopub.status.busy":"2022-01-12T02:23:16.904503Z","iopub.execute_input":"2022-01-12T02:23:16.905142Z","iopub.status.idle":"2022-01-12T02:23:17.295281Z","shell.execute_reply.started":"2022-01-12T02:23:16.905097Z","shell.execute_reply":"2022-01-12T02:23:17.294144Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"loss = chkpt['loss']['MSE_Loss']\nf = plt.figure(figsize=(20,8))\nax = f.add_subplot(1,2,1)\nax.plot(loss)\n# ax.set_yscale('log')\nax.set_title('MSE_Loss Loss')\nax.set_xlabel('Iteration')","metadata":{"execution":{"iopub.status.busy":"2022-01-12T02:23:17.296768Z","iopub.execute_input":"2022-01-12T02:23:17.298370Z","iopub.status.idle":"2022-01-12T02:23:17.602005Z","shell.execute_reply.started":"2022-01-12T02:23:17.298321Z","shell.execute_reply":"2022-01-12T02:23:17.601029Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}